# .github/workflows/job-scraper.yml
name: Automated Job Scraper

on:
  schedule:
    # Run 4 times a day: 6 AM, 12 PM, 6 PM, 12 AM UTC
    - cron: '0 6 * * *'   # 6 AM UTC
    - cron: '0 12 * * *'  # 12 PM UTC
    - cron: '0 18 * * *'  # 6 PM UTC
    - cron: '0 0 * * *'   # 12 AM UTC
  # Allow manual trigger
  workflow_dispatch:

jobs:
  scrape-jobs:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Setup Chrome and ChromeDriver
      uses: browser-actions/setup-chrome@v1
      with:
        chrome-version: stable
        install-chromedriver: true

    - name: Verify Chrome and ChromeDriver versions
      run: |
        google-chrome --version
        chromedriver --version

    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run job scraper
      env:
        GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
        GMAIL_EMAIL: ${{ secrets.GMAIL_EMAIL }}
        GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      run: python github_actions_job_scraper.py

    - name: Commit and push job data
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add job_data/
        git diff --staged --quiet || git commit -m "Update job data - $(date '+%Y-%m-%d %H:%M:%S')"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}